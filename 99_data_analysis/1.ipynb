{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube Data API를 위한 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-api-python-client pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env파일에서 YOUTUBE_API_KEY 가져오기\n",
    "import os\n",
    "api_key = os.getenv('YOUTUBE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize_youtube: \n",
    "Initializes the YouTube API client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_youtube(api_key):\n",
    "    return build('youtube', 'v3', developerKey=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search_channels: \n",
    "Searches for channels based on the provided keyword and returns a list of channel IDs and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_channels(youtube, query, max_results=10):\n",
    "    request = youtube.search().list(\n",
    "        q=query,\n",
    "        part=\"snippet\",\n",
    "        type=\"channel\",\n",
    "        maxResults=max_results\n",
    "    )\n",
    "    response = request.execute()\n",
    "    channels = []\n",
    "    for item in response['items']:\n",
    "        channels.append({\n",
    "            'channelId': item['snippet']['channelId'],\n",
    "            'channelTitle': item['snippet']['title']\n",
    "        })\n",
    "    return channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_channel_stats: \n",
    "Fetches the statistics of a specific channel, including subscriber count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_id):\n",
    "    request = youtube.channels().list(\n",
    "        part=\"statistics\",\n",
    "        id=channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response['items'][0]['statistics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_video_stats: \n",
    "Retrieves video statistics (likes, dislikes, views) for videos posted within a specified date range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_stats(youtube, channel_id, published_after, published_before):\n",
    "    request = youtube.search().list(\n",
    "        part=\"id,snippet\",\n",
    "        channelId=channel_id,\n",
    "        publishedAfter=published_after,\n",
    "        publishedBefore=published_before,\n",
    "        maxResults=50,\n",
    "        type=\"video\"\n",
    "    )\n",
    "    response = request.execute()\n",
    "    video_stats = []\n",
    "    for item in response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        video_details = get_video_details(youtube, video_id)\n",
    "        video_stats.append({\n",
    "            'videoId': video_id,\n",
    "            'title': item['snippet']['title'],\n",
    "            'publishedAt': item['snippet']['publishedAt'],\n",
    "            'viewCount': video_details.get('viewCount', 'N/A'),\n",
    "            'likeCount': video_details.get('likeCount', 'N/A'),\n",
    "            'dislikeCount': video_details.get('dislikeCount', 'N/A')\n",
    "        })\n",
    "    return video_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_video_details: \n",
    "Fetches detailed statistics for a specific video.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part=\"statistics\",\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    video_stats = response['items'][0]['statistics']\n",
    "    return video_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_video_comments: \n",
    "Collects all comments on a given video, handling pagination to fetch all comments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(youtube, video_id):\n",
    "    comments = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=100,\n",
    "        textFormat=\"plainText\"\n",
    "    )\n",
    "    response = request.execute()\n",
    "    while request:\n",
    "        response = request.execute()\n",
    "        for item in response['items']:\n",
    "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append({\n",
    "                'videoId': video_id,\n",
    "                'commentId': item['id'],\n",
    "                'authorDisplayName': top_comment['authorDisplayName'],\n",
    "                'textOriginal': top_comment['textOriginal'],\n",
    "                'likeCount': top_comment['likeCount'],\n",
    "                'publishedAt': top_comment['publishedAt']\n",
    "            })\n",
    "        request = youtube.commentThreads().list_next(request, response)\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main: \n",
    "Orchestrates the data collection and saves it to two CSV files (one for video stats and one for comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(api_key, query, start_date, end_date):\n",
    "    youtube = initialize_youtube(api_key)\n",
    "    \n",
    "    channels = search_channels(youtube, query)\n",
    "    print(\"Channels Found:\", channels)\n",
    "    \n",
    "    all_channel_stats = []\n",
    "    all_comments = []\n",
    "\n",
    "    for channel in channels:\n",
    "        channel_stats = get_channel_stats(youtube, channel['channelId'])\n",
    "        print(f\"Stats for {channel['channelTitle']}: {channel_stats}\")\n",
    "        \n",
    "        video_stats = get_video_stats(\n",
    "            youtube, \n",
    "            channel['channelId'], \n",
    "            start_date, \n",
    "            end_date\n",
    "        )\n",
    "        \n",
    "        for video_stat in video_stats:\n",
    "            all_channel_stats.append({\n",
    "                'channelTitle': channel['channelTitle'],\n",
    "                'channelId': channel['channelId'],\n",
    "                'subscribers': channel_stats.get('subscriberCount', 'N/A'),\n",
    "                'videoId': video_stat['videoId'],\n",
    "                'title': video_stat['title'],\n",
    "                'publishedAt': video_stat['publishedAt'],\n",
    "                'viewCount': video_stat['viewCount'],\n",
    "                'likeCount': video_stat['likeCount'],\n",
    "                'dislikeCount': video_stat['dislikeCount']\n",
    "            })\n",
    "            comments = get_video_comments(youtube, video_stat['videoId'])\n",
    "            all_comments.extend(comments)\n",
    "\n",
    "    df_stats = pd.DataFrame(all_channel_stats)\n",
    "    df_stats.to_csv('youtube_channel_stats.csv', index=False)\n",
    "    \n",
    "    df_comments = pd.DataFrame(all_comments)\n",
    "    df_comments.to_csv('youtube_video_comments.csv', index=False)\n",
    "\n",
    "    print(\"Data saved to youtube_channel_stats.csv and youtube_video_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage Notes:\n",
    " - Replace `YOUR_API_KEY` with your actual YouTube Data API key.\n",
    " - Adjust the `start_date` and `end_date` to your specific date range needs.\n",
    " - The script fetches up to 50 videos per channel due to API limits. Pagination handling for videos can be added for more extensive data collection.\n",
    "### Precautions:\n",
    " - **API Quota:** YouTube API calls consume quota, so monitor your usage in the Google Developer Console.\n",
    " - **Rate Limits:** Be aware of rate limits to avoid being temporarily blocked from making further API calls.\n",
    " - **Data Privacy:** Ensure compliance with YouTube's terms of service and data privacy policies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = 'YOUR_API_KEY'  # Replace with your YouTube Data API key\n",
    "    query = '주식정보제공채널'\n",
    "    start_date = '2022-01-01T00:00:00Z'  # Example start date\n",
    "    end_date = '2022-12-31T23:59:59Z'    # Example end date\n",
    "    main(api_key, query, start_date, end_date)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
