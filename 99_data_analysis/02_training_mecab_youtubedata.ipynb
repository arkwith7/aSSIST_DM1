{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv('./youtube_channel_comments_data_20240606_104600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56453 entries, 0 to 56452\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   channelId           56453 non-null  object\n",
      " 1   channelTitle        56453 non-null  object\n",
      " 2   channelPublishedAt  56453 non-null  object\n",
      " 3   subscriberCount     56453 non-null  int64 \n",
      " 4   videoId             56453 non-null  object\n",
      " 5   videoTitle          56453 non-null  object\n",
      " 6   videoAuthorId       56453 non-null  object\n",
      " 7   videoPublishedAt    56453 non-null  object\n",
      " 8   duration            56453 non-null  object\n",
      " 9   viewCount           56453 non-null  int64 \n",
      " 10  likeCount           56453 non-null  int64 \n",
      " 11  dislikeCount        56453 non-null  int64 \n",
      " 12  commentId           56453 non-null  object\n",
      " 13  commentAuthor       56325 non-null  object\n",
      " 14  authorId            56453 non-null  object\n",
      " 15  commentText         56449 non-null  object\n",
      " 16  commentLikeCount    56453 non-null  int64 \n",
      " 17  commentPublishedAt  56453 non-null  object\n",
      " 18  parentCommentId     27851 non-null  object\n",
      "dtypes: int64(5), object(14)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         야채 많이드시고 가끔 요구르트 챙겨드시면\\n어느정도 예방됨\n",
       "1                            제일 확실한건 변비 설사 반복 됩니다 꼭 검사해보셔요\n",
       "2                                           좋은정보 감사합니다 😊😊😊\n",
       "3                                        걸리면 하느님 만나로 올라갈게요\n",
       "4                                이중에 하나도 해당 안됐는데\\n대장암 4기..\n",
       "                               ...                        \n",
       "56448            이지약사님 정말 오랜만에 뵙네요 그동안 잘 지내셨나요\\n너무 보고 싶었어요\n",
       "56449                                     감사합니다 잘 지내셨죠~~!!\n",
       "56450    이지 약사님, 정말 오랜만에 뵙네요. 그동안 잘 지내셨나요?\\n너무 보고 싶었어요. ^^\n",
       "56451            안녕하세요 감사합니다..ㅎㅎ 부활해 보았습니당..ㅎㅎ 무더위 잘 보내셨죠!\n",
       "56452                 @@ezyaksa 이지 약사님을 이렇게 뵈니 너무 반갑네요. ㅎㅎ\n",
       "Name: commentText, Length: 56453, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaned_commentText의 데이터 보기\n",
    "data['commentText']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수 문자 제거 함수\n",
    "def clean_text(text):\n",
    "    # 줄바꿈 문자 포함하여 특수 문자 제거\n",
    "    text = re.sub(r'[^ㄱ-ㅎ가-힣0-9\\s]', '', text)\n",
    "    # \"ㅎㅎ\", \"ㅋㅋ\" 등 비정식 단어 제거\n",
    "    text = re.sub(r'ㅎㅎ|ㅋㅋ', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # 공백 문자를 하나의 공백으로 치환하고 양쪽 공백 제거\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 값 제거\n",
    "data = data.dropna(subset=['commentText'])\n",
    "\n",
    "# NaN 값 공백 문자열로 대체\n",
    "data['commentText'] = data['commentText'].fillna('')\n",
    "\n",
    "# 댓글, 답글 데이터 전처리\n",
    "data['cleaned_commentText'] = data['commentText'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  야채 많이드시고 가끔 요구르트 챙겨드시면 어느정도 예방됨\n",
       "1                    제일 확실한건 변비 설사 반복 됩니다 꼭 검사해보셔요\n",
       "2                                       좋은정보 감사합니다\n",
       "3                                걸리면 하느님 만나로 올라갈게요\n",
       "4                           이중에 하나도 해당 안됐는데 대장암 4기\n",
       "                           ...                    \n",
       "56448     이지약사님 정말 오랜만에 뵙네요 그동안 잘 지내셨나요 너무 보고 싶었어요\n",
       "56449                                 감사합니다 잘 지내셨죠\n",
       "56450    이지 약사님 정말 오랜만에 뵙네요 그동안 잘 지내셨나요 너무 보고 싶었어요\n",
       "56451             안녕하세요 감사합니다 부활해 보았습니당 무더위 잘 보내셨죠\n",
       "56452                       이지 약사님을 이렇게 뵈니 너무 반갑네요\n",
       "Name: cleaned_commentText, Length: 56449, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_commentText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('순', 'MM'), ('대국', 'NNG'), ('먹', 'VV'), ('고', 'EC'), ('싶', 'VX'), ('다', 'EF'), ('.', 'SF')]\n",
      "[('순댓국', 'NNG'), ('먹', 'VV'), ('고', 'EC'), ('싶', 'VX'), ('다', 'EF'), ('.', 'SF')]\n",
      "[('패스트', 'NNP'), ('파이브', 'NNP'), ('에서', 'JKB'), ('일', 'NNG'), ('을', 'JKO'), ('합니다', 'VV+EF'), ('.', 'SF')]\n",
      "[('아이오', 'NNG'), ('아이', 'NNG'), ('는', 'JX'), ('정말', 'MAG'), ('이뻐요', 'VA+EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "m = Mecab()\n",
    "\n",
    "print(m.pos(\"순대국 먹고 싶다.\"))\n",
    "print(m.pos(\"순댓국 먹고 싶다.\"))\n",
    "print(m.pos(\"패스트파이브에서 일을 합니다.\"))\n",
    "print(m.pos(\"아이오아이는 정말 이뻐요.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(text):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에서 명사만 추출하여 반환하는 함수.\n",
    "    \n",
    "    Args:\n",
    "    text (str): 명사를 추출할 텍스트.\n",
    "    \n",
    "    Returns:\n",
    "    list: 추출된 명사들의 리스트.\n",
    "    \"\"\"\n",
    "    # Mecab의 noun 메소드를 사용하여 명사 추출\n",
    "    nouns = m.nouns(text)\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['패스트', '파이브', '일', '오', '아이']\n"
     ]
    }
   ],
   "source": [
    "# 예제 사용\n",
    "example_text = \"패스트파이브에서 일을 합니다. 아이오아이는 정말 이뻐요.\"\n",
    "nouns = extract_nouns(example_text)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 텍스트 토크나이징\n",
    "토크나이저를 사용하여 텍스트 데이터를 토큰화합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['tokenized'] = data['cleaned_commentText'].apply(extract_nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTokenizer\n",
    "# 한글자, 지시대명사 등 제거\n",
    "data['tokenized'] = data['tokenized'].apply(lambda x: [item for item in x if len(item) > 1])\n",
    "\n",
    "# 한글자 이외의 형용사, 부사, 동사 불용어 stopword 목록 작성하여 반영\n",
    "stopword = ['ㅎㅎ', 'ㅋㅋ', 'ㅠㅠ', 'ㅜㅜ', 'ㅇㅇ', 'ㅈㅈ', 'ㅊㅊ', 'ㅋㅋ', 'ㅎㅎ', 'ㅇㅇ', 'ㅈㅈ', 'ㅊㅊ']\n",
    "data['tokenized'] = data['tokenized'].apply(lambda x: [item for item in x if item not in stopword])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0:\n",
      "Tokenized:  ['야채', '요구르트', '정도', '예방']\n",
      "Row 1:\n",
      "Tokenized:  ['변비', '반복', '검사']\n",
      "Row 2:\n",
      "Tokenized:  ['정보', '감사']\n",
      "Row 3:\n",
      "Tokenized:  ['하느님', '만나', '게요']\n",
      "Row 4:\n",
      "Tokenized:  ['하나', '해당', '대장암']\n",
      "Row 5:\n",
      "Tokenized:  []\n",
      "Row 6:\n",
      "Tokenized:  []\n",
      "Row 7:\n",
      "Tokenized:  []\n",
      "Row 8:\n",
      "Tokenized:  []\n",
      "Row 9:\n",
      "Tokenized:  ['체중', '감소', '안심']\n",
      "Row 10:\n",
      "Tokenized:  ['질병', '사람']\n",
      "Row 11:\n",
      "Tokenized:  ['내츄럴', '터스', '베르베린', '휴지기']\n",
      "Row 12:\n",
      "Tokenized:  ['마지막', '제품', '내츄럴', '터스', '베르베린', '리포', '미셀', '구매', '하루', '섭취', '건가요']\n",
      "Row 13:\n",
      "Tokenized:  ['당뇨', '환자', '영양제']\n",
      "Row 14:\n",
      "Tokenized:  ['요즘', '알코', '클렌', '니코틴', '알코올', '분해', '영양제', '광고', '약국', '판매', '효과', '건가요']\n",
      "Row 15:\n",
      "Tokenized:  ['당뇨병', '당뇨병', '채소', '결국', '당뇨', '경우', '영양제', '지병', '영양제', '유산균', '비타민', '비타민', '마그네슘', '엽산', '가지', '간수', '검사', '당뇨']\n",
      "Row 16:\n",
      "Tokenized:  ['오메가', '부작용']\n",
      "Row 17:\n",
      "Tokenized:  ['바나바', '베르베린', '섭취', '당뇨', '환자', '개월', '정도', '증상']\n",
      "Row 18:\n",
      "Tokenized:  ['약사', '평소', '폐경', '이후', '영양제', '에스트로겐', '섭취', '얘기']\n",
      "Row 19:\n",
      "Tokenized:  ['폐경', '이후', '섭취', '기본', '마비', '디유', '이소', '플라본', '미오', '이노시톨', '에스트로겐', '관련', '제품', '건강', '관련', '칼슘', '마그네슘', '비타민', '철분', '부족', '철분', '정도']\n",
      "Row 20:\n",
      "Tokenized:  ['텐데', '감사']\n",
      "Row 21:\n",
      "Tokenized:  ['의사', '구매', '의사', '처방']\n",
      "Row 22:\n",
      "Tokenized:  ['섭취', '증상', '치료', '말씀', '정도', '말씀', '그게', '경우', '말씀', '부분', '양해', '부탁']\n",
      "Row 23:\n",
      "Tokenized:  ['아이오딘', '오다', '이드', '추천']\n",
      "Row 24:\n",
      "Tokenized:  ['상품', '추천', '광고', '오해', '소지', '양해', '부탁']\n",
      "Row 25:\n",
      "Tokenized:  ['약사', '정보', '감사', '베르베린', '부작용', '백혈구', '수치', '감소']\n",
      "Row 26:\n",
      "Tokenized:  ['부작용', '가지', '이건', '케이스', '면역', '반응', '이상', '경우', '베르베린', '정상', '감소', '얘기']\n",
      "Row 27:\n",
      "Tokenized:  ['개월', '만성', '염증', '영상', '자임', '자임', '계속', '품절', '메가', '자임', '주요', '성분', '메가', '자임', '복용', '위산', '과다증', '사람', '복용', '런지']\n",
      "Row 28:\n",
      "Tokenized:  ['성분', '함량', '섭취', '복용', '위산', '과다', '섭취', '가능']\n",
      "Row 29:\n",
      "Tokenized:  ['베르베린', '여성', '호르몬', '성분', '여자', '수술', '석류', '자몽']\n",
      "Row 30:\n",
      "Tokenized:  ['여성', '호르몬', '부분']\n",
      "Row 31:\n",
      "Tokenized:  ['감사', '약사', '영상', '마비', '구매', '혈압', '마비', '여기', '추천', '하나', '추가']\n",
      "Row 32:\n",
      "Tokenized:  ['항혈전제', '섭취', '생각']\n",
      "Row 33:\n",
      "Tokenized:  ['감사']\n",
      "Row 34:\n",
      "Tokenized:  ['나우', '푸드', '베르베', '섭취', '이것', '가요', '성분']\n",
      "Row 35:\n",
      "Tokenized:  ['특정', '제품', '언급', '광고', '오해', '소지', '양해', '부탁']\n",
      "Row 36:\n",
      "Tokenized:  ['제품']\n",
      "Row 37:\n",
      "Tokenized:  ['약사', '식단', '음식', '귀리', '가슴살', '호두', '단지', '귀리', '하루', '섭취', '귀리', '투퍼', '데이', '가슴살', '하루', '아연', '취량', '종합', '비타민', '자연식', '영양제', '흡수']\n",
      "Row 38:\n",
      "Tokenized:  []\n",
      "Row 39:\n",
      "Tokenized:  ['아침', '공복', '식후', '공복', '아침', '유산균', '보울', '라디', '글루', '타치', '알파', '리포산', '섭취', '섭취']\n",
      "Row 40:\n",
      "Tokenized:  ['점심', '공복', '저녁', '공복', '섭취']\n",
      "Row 41:\n",
      "Tokenized:  ['댓글', '감사']\n",
      "Row 42:\n",
      "Tokenized:  ['구매', '시기']\n",
      "Row 43:\n",
      "Tokenized:  ['도움', '다행']\n",
      "Row 44:\n",
      "Tokenized:  ['이노시톨', '복용', '이것', '혈당', '작용', '걸까요', '복용']\n",
      "Row 45:\n",
      "Tokenized:  ['보조', '활용', '가능']\n",
      "Row 46:\n",
      "Tokenized:  ['약사', '베리', '마취']\n",
      "Row 47:\n",
      "Tokenized:  ['도움', '다행']\n",
      "Row 48:\n",
      "Tokenized:  ['알약', '종류']\n",
      "Row 49:\n",
      "Tokenized:  ['섭취']\n",
      "Row 50:\n",
      "Tokenized:  ['당뇨', '사람']\n",
      "Row 51:\n",
      "Tokenized:  ['혈당', '유지', '용량', '시작']\n",
      "Row 52:\n",
      "Tokenized:  ['혈압', '효과']\n",
      "Row 53:\n",
      "Tokenized:  ['보조', '활용', '가능']\n",
      "Row 54:\n",
      "Tokenized:  ['안녕', '센트', '구미', '아이', '구미', '영양제', '지요', '오메가', '동시', '걸로', '구미', '제품', '영상', '주심', '감사']\n",
      "Row 55:\n",
      "Tokenized:  ['기호', '내용', '참고']\n",
      "Row 56:\n",
      "Tokenized:  ['내츄럴', '터스', '베르베린', '리포', '미셀', '스완슨', '어드밴스', '제품', '추천', '암거', '마음']\n",
      "Row 57:\n",
      "Tokenized:  ['이건', '개인', '선택', '이거', '말씀']\n",
      "Row 58:\n",
      "Tokenized:  ['약사', '마티스', '고지', '고혈압', '부정맥', '디스크', '신경', '증약', '퇴행', '관절염', '복용']\n",
      "Row 59:\n",
      "Tokenized:  ['항혈전제', '섭취', '문제']\n",
      "Row 60:\n",
      "Tokenized:  ['라레이', '베르베린', '품절', '이거', '느낌', '가지', '질문', '베르베린', '공복', '식후']\n",
      "Row 61:\n",
      "Tokenized:  ['공복', '섭취', '흡수율', '생각']\n",
      "Row 62:\n",
      "Tokenized:  ['비타민', '섭취']\n",
      "Row 63:\n",
      "Tokenized:  []\n",
      "Row 64:\n",
      "Tokenized:  ['베르베린', '부작용', '장내', '세균', '사실', '단독', '장기간', '복용', '건가요']\n",
      "Row 65:\n",
      "Tokenized:  ['용량', '섭취', '생각']\n",
      "Row 66:\n",
      "Tokenized:  ['안녕', '약사', '부모', '영양제', '공부', '사람', '베르베린', '구매', '과민성', '대장', '증후군', '사람', '효과', '프로', '바이오', '상관', '유산균', '약사', '추천', '노란색', '박스', '변비', '아침', '빈속', '프로', '바이오', '저녁', '베르베린']\n",
      "Row 67:\n",
      "Tokenized:  ['베르베린', '오전', '유산균', '저녁', '섭취', '권장']\n",
      "Row 68:\n",
      "Tokenized:  ['안녕', '성분', '표기', '변환']\n",
      "Row 69:\n",
      "Tokenized:  ['이건', '성분', '보통']\n",
      "Row 70:\n",
      "Tokenized:  ['당뇨', '베르', '베른', '복용', '중단', '나이', '근육']\n",
      "Row 71:\n",
      "Tokenized:  ['유청', '단백질', '성분', '섭취']\n",
      "Row 72:\n",
      "Tokenized:  ['선생', '정보', '감사', '당뇨', '진단', '방약', '병행', '복용', '건지']\n",
      "Row 73:\n",
      "Tokenized:  ['혈당', '유지', '섭취']\n",
      "Row 74:\n",
      "Tokenized:  ['작년', '유방암', '수술', '방사선', '항암', '개월', '베르베린', '복용']\n",
      "Row 75:\n",
      "Tokenized:  ['치료', '복용', '문제']\n",
      "Row 76:\n",
      "Tokenized:  ['내추럴', '터스', '리포', '미셀', '저거', '약사', '영상', '업자', '가격', '배송', '취소', '결국', '취소', '가격', '캐나다']\n",
      "Row 77:\n",
      "Tokenized:  []\n",
      "Row 78:\n",
      "Tokenized:  ['약사', '네츄럴', '터스', '복용']\n",
      "Row 79:\n",
      "Tokenized:  ['공복', '섭취']\n",
      "Row 80:\n",
      "Tokenized:  ['전립선']\n",
      "Row 81:\n",
      "Tokenized:  ['안녕', '양질', '아연', '호박씨', '추출물', '라이코', '기본', '베이스', '조합', '베타', '스테롤', '전립선염', '도움']\n",
      "Row 82:\n",
      "Tokenized:  ['베타', '스테롤', '구입', '감사']\n",
      "Row 83:\n",
      "Tokenized:  ['언제', '복용']\n",
      "Row 84:\n",
      "Tokenized:  ['보통', '정도', '섭취', '중단']\n",
      "Row 85:\n",
      "Tokenized:  ['당뇨', '메타', '포민', '밀리', '베르베린']\n",
      "Row 86:\n",
      "Tokenized:  ['혈당', '유지', '경우', '용량', '섭취']\n",
      "Row 87:\n",
      "Tokenized:  ['식전', '식후', '복용', '효과', '가요']\n",
      "Row 88:\n",
      "Tokenized:  ['공복', '섭취', '권장']\n",
      "Row 89:\n",
      "Tokenized:  ['사비', '사비', '식전', '베르베린', '식전']\n",
      "Row 90:\n",
      "Tokenized:  ['섭취', '권장']\n",
      "Row 91:\n",
      "Tokenized:  ['선생', '선염', '재발', '고생', '전립선염', '영양제', '오메가', '지방산', '전립선염', '도움', '적정', '염증', '개선', '전립선암', '유발', '고민', '그리거', '라이코', '영양제', '도움']\n",
      "Row 92:\n",
      "Tokenized:  ['안녕', '양질', '아연', '호박씨', '추출물', '라이코', '기본', '베이스', '조합', '베타', '스테롤', '전립선염', '도움']\n",
      "Row 93:\n",
      "Tokenized:  ['답글', '감사', '호박씨', '추출물', '직구', '주문', '라이코', '영양제', '나우', '푸드', '걸로', '쿠팡', '직구', '브랜드', '추천']\n",
      "Row 94:\n",
      "Tokenized:  ['약사', '단추', '어디', '감사']\n",
      "Row 95:\n",
      "Tokenized:  ['말씀', '양해', '부탁']\n",
      "Row 96:\n",
      "Tokenized:  ['변비', '사람', '베르베린', '장내', '유익', '걱정', '혈당', '때문', '베르베린', '복용']\n",
      "Row 97:\n",
      "Tokenized:  ['베르베린', '오전', '공복', '섭취', '저녁', '공복', '유산균', '섭취']\n",
      "Row 98:\n",
      "Tokenized:  ['쿠팡', '이상', '물건', '쿠팡', '선택', '댓글', '허브']\n",
      "Row 99:\n",
      "Tokenized:  ['후기', '감사']\n",
      "Row 100:\n",
      "Tokenized:  ['셔츠', '좌표', '부탁']\n",
      "Row 101:\n",
      "Tokenized:  ['좌표', '양해', '부탁']\n"
     ]
    }
   ],
   "source": [
    "# 각 행에 대해 l_tokenized와 maxscore_tokenized 결과를 함께 출력\n",
    "for index, row in data.iterrows():\n",
    "    print(f\"Row {index}:\")\n",
    "    print(\"Tokenized: \", row['tokenized'])\n",
    "    # print(\"MaxScore Tokenized: \", row['maxscore_tokenized'])\n",
    "    # print(\"\\n\")\n",
    "    if index > 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channelId\n",
       "UC3iSLVH0MxHfwO69oHKpvog    [리틀, 약사, 최고, 감사, 비문증, 브로멜, 라인, 파파인, 설명, 리틀, 약사...\n",
       "UC6ggXTuBVchhwHeQ12Ita1w    [베르베린, 복용, 방법, 안내, 복용량, 점진, 증량, 처음, 하루, 시작, 하루...\n",
       "UCCMFTDGarjgZLc1DlIbbvRg    [감사, 사람, 소화, 열량, 셀룰로오스, 흡수, 스펀지, 역할, 약사, 스타, 스...\n",
       "UCMFk5S7g5DY-CZNVh_Kyz_A    [야채, 요구르트, 정도, 예방, 변비, 반복, 검사, 정보, 감사, 하느님, 만나...\n",
       "UCY-mXLM6DsS9cmSwlh0tqSA    [하루, 아르기닌, 변비, 유산균, 공구, 오픈, 구매, 링크, 트랜, 유산균, 유...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채널별로 데이터 그룹화 및 토큰 리스트 합치기\n",
    "grouped_data = data.groupby('channelId')['tokenized'].agg(lambda x: [token for sublist in x for token in sublist])\n",
    "grouped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 채널별로 상위 20개 단어 추출\n",
    "top_words_per_channel = {}\n",
    "for channel_id, tokens in grouped_data.items():\n",
    "    # 토큰의 빈도수 계산\n",
    "    token_counts = Counter(tokens)\n",
    "    # 가장 빈번한 30개 단어 추출\n",
    "    top_words = token_counts.most_common(30)\n",
    "    top_words_per_channel[channel_id] = top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel UC3iSLVH0MxHfwO69oHKpvog:\n",
      "감사: 1333\n",
      "약사: 1049\n",
      "비타민: 745\n",
      "마그네슘: 640\n",
      "상담: 615\n",
      "제품: 592\n",
      "영양제: 580\n",
      "리틀: 562\n",
      "영상: 522\n",
      "밴드: 517\n",
      "복용: 516\n",
      "오메가: 494\n",
      "사람: 410\n",
      "건강: 401\n",
      "네이버: 399\n",
      "섭취: 376\n",
      "정도: 369\n",
      "효과: 361\n",
      "도움: 352\n",
      "정보: 337\n",
      "하루: 324\n",
      "답변: 309\n",
      "커피: 303\n",
      "유튜브: 286\n",
      "시간: 285\n",
      "생각: 282\n",
      "음식: 277\n",
      "문제: 252\n",
      "이용: 249\n",
      "불편: 245\n",
      "\n",
      "\n",
      "Channel UC6ggXTuBVchhwHeQ12Ita1w:\n",
      "감사: 712\n",
      "복용: 658\n",
      "약사: 590\n",
      "영상: 335\n",
      "제품: 270\n",
      "섭취: 263\n",
      "영양제: 244\n",
      "정보: 235\n",
      "효과: 233\n",
      "레스: 198\n",
      "선생: 178\n",
      "건강: 177\n",
      "피세: 173\n",
      "베르베린: 166\n",
      "멜라토닌: 165\n",
      "도움: 164\n",
      "안녕: 144\n",
      "추천: 142\n",
      "미국: 139\n",
      "비타민: 129\n",
      "아침: 123\n",
      "구매: 122\n",
      "베라트: 119\n",
      "정도: 118\n",
      "하루: 113\n",
      "베라: 113\n",
      "피부: 98\n",
      "구입: 94\n",
      "개월: 87\n",
      "트롤: 87\n",
      "\n",
      "\n",
      "Channel UCCMFTDGarjgZLc1DlIbbvRg:\n",
      "감사: 90\n",
      "크림: 46\n",
      "약사: 45\n",
      "효과: 37\n",
      "지약: 31\n",
      "제품: 28\n",
      "멜라토: 25\n",
      "정보: 22\n",
      "피부: 21\n",
      "영상: 20\n",
      "노사: 20\n",
      "멜라: 19\n",
      "부위: 16\n",
      "여드름: 15\n",
      "색소: 15\n",
      "이지: 14\n",
      "약국: 14\n",
      "오랜만: 14\n",
      "침착: 13\n",
      "흉터: 13\n",
      "흡수: 12\n",
      "안녕: 12\n",
      "자외선: 12\n",
      "처방: 11\n",
      "얼굴: 11\n",
      "추천: 11\n",
      "이거: 10\n",
      "함량: 10\n",
      "정도: 10\n",
      "소화: 9\n",
      "\n",
      "\n",
      "Channel UCMFk5S7g5DY-CZNVh_Kyz_A:\n",
      "감사: 8574\n",
      "섭취: 5627\n",
      "약사: 4468\n",
      "비타민: 4299\n",
      "영양제: 3742\n",
      "오메가: 3700\n",
      "제품: 3412\n",
      "복용: 3104\n",
      "영상: 2859\n",
      "도움: 2488\n",
      "시청: 2363\n",
      "추천: 2279\n",
      "마그네슘: 1897\n",
      "부탁: 1876\n",
      "생각: 1819\n",
      "말씀: 1662\n",
      "정도: 1624\n",
      "효과: 1545\n",
      "정보: 1534\n",
      "문제: 1504\n",
      "유산균: 1361\n",
      "성분: 1306\n",
      "건강: 1227\n",
      "하루: 1163\n",
      "사람: 1102\n",
      "당뇨: 1095\n",
      "안녕: 1072\n",
      "구매: 1038\n",
      "양해: 1036\n",
      "때문: 970\n",
      "\n",
      "\n",
      "Channel UCY-mXLM6DsS9cmSwlh0tqSA:\n",
      "감사: 1444\n",
      "영양제: 1382\n",
      "추천: 1320\n",
      "제품: 1116\n",
      "비타민: 1111\n",
      "양과자: 1001\n",
      "구매: 664\n",
      "도움: 623\n",
      "유산균: 611\n",
      "영상: 597\n",
      "오메가: 437\n",
      "검사: 432\n",
      "복용: 414\n",
      "멀티: 349\n",
      "하루: 345\n",
      "마그네슘: 335\n",
      "섭취: 331\n",
      "미네랄: 331\n",
      "허브: 319\n",
      "효과: 313\n",
      "콜라겐: 304\n",
      "아이: 303\n",
      "모발: 293\n",
      "링크: 286\n",
      "쿠팡: 285\n",
      "영양: 261\n",
      "칼슘: 258\n",
      "추가: 257\n",
      "아르기닌: 251\n",
      "공구: 244\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for channel_id, words in top_words_per_channel.items():\n",
    "    print(f\"Channel {channel_id}:\")\n",
    "    for word, count in words:\n",
    "        print(f\"{word}: {count}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
